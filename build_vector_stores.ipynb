{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run useful_functions.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "In a previous notebook - `text_splitter_eval.ipynb`, we pickled a list of chunked text. Now it's time to persist the different chunked texts into vector stores so that we can persist them and use them for querying.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the chunked text\n",
    "Load the chunked texts from the pickled file. From the table, we can see we have split the text with four differently configured splitters.  Three are `CharacterTextSplitter` and one is `NLTKTextSplitter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "| Index | Splitter | Number of Chunks | Chunk Size | Overlap Size |\n",
       "|---|---|---|---|---|\n",
       "| 0 | CharacterTextSplitter | 751 | 100 | 20 |\n",
       "| 1 | CharacterTextSplitter | 75 | 1000 | 200 |\n",
       "| 2 | CharacterTextSplitter | 16 | 4000 | 200 |\n",
       "| 3 | NLTKTextSplitter | 16 | 3894 | 0 |\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('chunks_list.pkl', 'rb') as f:\n",
    "    chunked_texts = pickle.load(f)\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Create the markdown table\n",
    "markdown_table = \"| Index | Splitter | Number of Chunks | Chunk Size | Overlap Size |\\n|---|---|---|---|---|\\n\"\n",
    "for i, chunk in enumerate(chunked_texts):\n",
    "    markdown_table += \"| \" + \" | \".join(str(x) for x in [i, chunk['type'], len(chunk['chunks']), chunk['chunk_size'], chunk['overlap_size']]) + \" |\\n\"\n",
    "\n",
    "# Display the markdown table\n",
    "display(Markdown(markdown_table))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets take our splits and embed them.  We'll be using OpenAIEmbeddings for no particular reason than the docs use them.  Yet, they cost $$$ and we should evaluate other Open Source alternatives that might be as good or better with no cost.\n",
    "\n",
    "Sadly, figuring out the cost can be a tad difficult."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "| model | encoding |\n",
       "| --- | --- |\n",
       "| gpt-4 | cl100k_base |\n",
       "| gpt-3.5-turbo | cl100k_base |\n",
       "| text-davinci-003 | p50k_base |\n",
       "| text-davinci-002 | p50k_base |\n",
       "| text-davinci-001 | r50k_base |\n",
       "| text-curie-001 | r50k_base |\n",
       "| text-babbage-001 | r50k_base |\n",
       "| text-ada-001 | r50k_base |\n",
       "| davinci | r50k_base |\n",
       "| curie | r50k_base |\n",
       "| babbage | r50k_base |\n",
       "| ada | r50k_base |\n",
       "| code-davinci-002 | p50k_base |\n",
       "| code-davinci-001 | p50k_base |\n",
       "| code-cushman-002 | p50k_base |\n",
       "| code-cushman-001 | p50k_base |\n",
       "| davinci-codex | p50k_base |\n",
       "| cushman-codex | p50k_base |\n",
       "| text-davinci-edit-001 | p50k_edit |\n",
       "| code-davinci-edit-001 | p50k_edit |\n",
       "| text-embedding-ada-002 | cl100k_base |\n",
       "| text-similarity-davinci-001 | r50k_base |\n",
       "| text-similarity-curie-001 | r50k_base |\n",
       "| text-similarity-babbage-001 | r50k_base |\n",
       "| text-similarity-ada-001 | r50k_base |\n",
       "| text-search-davinci-doc-001 | r50k_base |\n",
       "| text-search-curie-doc-001 | r50k_base |\n",
       "| text-search-babbage-doc-001 | r50k_base |\n",
       "| text-search-ada-doc-001 | r50k_base |\n",
       "| code-search-babbage-code-001 | r50k_base |\n",
       "| code-search-ada-code-001 | r50k_base |\n",
       "| gpt2 | gpt2 |\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# returns a list of dictionaries with the key being a string representing the name of the LLM model and one property, an encoding string representing the encoding method used in the LLM model.\n",
    "encoding_lookup_dict = utils_get_llm_names_and_encoding()\n",
    "\n",
    "# Get the keys from the first dictionary to use as column headers\n",
    "headers = encoding_lookup_dict[0].keys()\n",
    "\n",
    "# Create the markdown table\n",
    "markdown_table = \"| \" + \" | \".join(headers) + \" |\\n| \" + \" | \".join(\"---\" for _ in headers) + \" |\\n\"\n",
    "for item in l:\n",
    "    markdown_table += \"| \" + \" | \".join(str(item[key]) for key in headers) + \" |\\n\"\n",
    "\n",
    "# Display the markdown table\n",
    "display(Markdown(markdown_table))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for OpenAIEmbeddings\ncallbacks\n  extra fields not permitted (type=value_error.extra)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39membeddings\u001b[39;00m \u001b[39mimport\u001b[39;00m OpenAIEmbeddings\n\u001b[0;32m      3\u001b[0m \u001b[39m# Create an OpenAIEmbeddings instance with your callback handler\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m embedding \u001b[39m=\u001b[39m OpenAIEmbeddings(callbacks\u001b[39m=\u001b[39;49mcallback_handler)\n",
      "File \u001b[1;32mc:\\Users\\happy\\Documents\\Projects\\explore_langchain\\.venv\\lib\\site-packages\\pydantic\\main.py:341\u001b[0m, in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValidationError\u001b[0m: 1 validation error for OpenAIEmbeddings\ncallbacks\n  extra fields not permitted (type=value_error.extra)"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "# Create an OpenAIEmbeddings instance with your callback handler\n",
    "embedding = OpenAIEmbeddings(callbacks=callback_handler)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we access an OpenAI call, we need to pass in the openai key.  This is handled by the `preamble` notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:numexpr.utils:Note: NumExpr detected 16 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "Note: NumExpr detected 16 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "INFO:numexpr.utils:NumExpr defaulting to 8 threads.\n",
      "NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "%run preamble.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
